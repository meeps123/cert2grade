{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, PPStructure, draw_ocr, save_structure_res\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import regex\n",
    "import fitz\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = [\n",
    "    {'name': 'general paper', 'level': 1, 'grade': 'a'}, \n",
    "    {'name': 'economics', 'level': 1, 'grade': 'a'}, \n",
    "    {'name': 'chemistry', 'level': 2, 'grade': 'a'}, \n",
    "    {'name': 'physics', 'level': 2, 'grade': 'a'}, \n",
    "    {'name': 'mathematics', 'level': 2, 'grade': 'a'}, \n",
    "    {'name': 'project work', 'level': 1, 'grade': 'a'}\n",
    "]\n",
    "grade_to_h1rp = {\n",
    "    'a': 10,\n",
    "    'b': 8.75,\n",
    "    'c': 7.5,\n",
    "    'd': 6.25,\n",
    "    'e': 5,\n",
    "    's': 2.5,\n",
    "    'u': 0\n",
    "}\n",
    "def calculate_rank_points(subjects):\n",
    "    h1_subjs = [subj for subj in subjects if subj['level'] == 1]\n",
    "    h1_subjs.sort(key=lambda x: x['grade'])\n",
    "    h2_subjs = [subj for subj in subjects if subj['level'] == 2]\n",
    "    h2_subjs.sort(key=lambda x: x['grade'])\n",
    "\n",
    "    if len(h2_subjs) == 4: # 4H2 2H1 case, treat weakest H2 as a H1\n",
    "        h2_subjs[-1]['level'] = 1\n",
    "        h1_subjs.append(h2_subjs[-1]) # Move to h1 array\n",
    "        del h2_subjs[-1]\n",
    "\n",
    "    rp = 0.0\n",
    "\n",
    "    for h1 in h1_subjs:\n",
    "        rp += grade_to_h1rp[h1['grade']]\n",
    "    for h2 in h2_subjs:\n",
    "        rp += grade_to_h1rp[h2['grade']]*2\n",
    "    \n",
    "    return rp\n",
    "        \n",
    "calculate_rank_points(subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/12/09 13:03:01] ppocr WARNING: When args.layout is false, args.ocr is automatically set to false\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_INPUT_DIR = '../data/input/'\n",
    "GLOBAL_OCR = PaddleOCR(use_angle_cls=True, lang='en', show_log=False)\n",
    "GLOBAL_PPSTRUCTURE = PPStructure(layout=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'general paper h1 a cambridge chemistry h2 a cambridge biology h2 economics a cambridge h2 mathematics a cambridge \"proteomics h2 a cambridge h3 dist cambridge '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = GLOBAL_PPSTRUCTURE('../data/by_type/6_alvl/alvl/img/alvlcert.jpeg', return_ocr_result_in_table=True)\n",
    "full_str = ' '.join([x[0] for x in result[0]['res']['rec_res']]).lower()\n",
    "subj_str = regex.search(r'(grade\\s*authority\\s*(.*)\\s*director\\-general){e<=7}', full_str).group(2)\n",
    "# subj_list = regex.split(r'\\s*cambridge\\s*', subj_str, maxsplit=0)\n",
    "subj_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olvl\n"
     ]
    }
   ],
   "source": [
    "input_path = os.path.join(GLOBAL_INPUT_DIR, os.listdir(GLOBAL_INPUT_DIR)[0])\n",
    "\n",
    "def churn(input_file):\n",
    "    # Reject input file if it is not a PDF\n",
    "    if os.path.splitext(input_file)[-1] != '.pdf':\n",
    "        raise Exception('Input file is not a PDF.')\n",
    "    \n",
    "    # OCR the entire PDF\n",
    "    result = GLOBAL_OCR.ocr(input_file, cls=True)\n",
    "\n",
    "    # Consider the first page of the PDF to classify the general type of document.\n",
    "    # The general classification will be used to do a type-specific analysis which will give the desired output.\n",
    "    first_page_texts = [line[1][0] for line in result[0]]\n",
    "    merged_text = ' '.join(first_page_texts).lower()\n",
    "    category_counts = {}\n",
    "    categories = {\n",
    "        'nlvl' : r'normal\\s*\\(\\w+\\)\\s*level', # for n-level\n",
    "        'olvl' : r'ordinary\\s*level', # for o-level\n",
    "        'ite' : r'national\\s*ite\\s*certificate\\sin', # for NITEC or Higher NTIEC\n",
    "        'poly' : r'polytechnic', # for poly\n",
    "        'ted' : r'technical\\s*engineer\\s*diploma', # for TED\n",
    "        'alvl' : r'advanced\\s*level', # for a-level\n",
    "        'ib' : r'baccalaureate', # for IB\n",
    "        'nush' : r'nus\\s*high' # for NUS High\n",
    "    }\n",
    "    for category in categories:\n",
    "        pattern = '(' + categories[category] + '){e<=1}'\n",
    "        category_counts[category] = len(regex.findall(pattern, merged_text))\n",
    "    max_count_category = max(category_counts, key=category_counts.get)\n",
    "    if max_count_category == 'psle':\n",
    "        print('psle')\n",
    "    elif max_count_category == 'nlvl':\n",
    "        print('nlvl')\n",
    "    elif max_count_category == 'olvl':\n",
    "        print('olvl')\n",
    "    elif max_count_category == 'ite':\n",
    "        # Further differentiate between NITEC and H.NITEC\n",
    "        if len(regex.findall(r'(higher\\s*national\\s*ite\\s*certificate\\sin){e<=1}', merged_text)):\n",
    "            # its a Higher NITEC\n",
    "            print('higher_nitec')\n",
    "        else:\n",
    "            print('nitec')\n",
    "    elif max_count_category == 'poly':\n",
    "        # Further differentiate between the 5 local polys\n",
    "        polys = {\n",
    "            'rp': r'republic',\n",
    "            'np': r'ngee\\s*ann',\n",
    "            'nyp': r'nanyang',\n",
    "            'tp': r'temasek',\n",
    "            'sp': r'singapore'\n",
    "        }\n",
    "        poly_counts = {}\n",
    "        for poly in polys:\n",
    "            poly_pattern = '(' + polys[poly] + '){e<=1}'\n",
    "            poly_counts[poly] = len(regex.findall(poly_pattern, merged_text))\n",
    "        max_count_poly = max(poly_counts, key=poly_counts.get)\n",
    "        if max_count_poly == 'rp':\n",
    "            print('rp')\n",
    "        elif max_count_poly == 'np':\n",
    "            print('np')\n",
    "        elif max_count_poly == 'nyp':\n",
    "            print('nyp')\n",
    "        elif max_count_poly == 'tp':\n",
    "            print('tp')\n",
    "        elif max_count_poly == 'sp':\n",
    "            print('sp')\n",
    "    elif max_count_category == 'ted':\n",
    "        print('ted')\n",
    "    elif max_count_category == 'alvl':\n",
    "        print('alvl')\n",
    "    elif max_count_category == 'ib':\n",
    "        print('ib')\n",
    "    elif max_count_category == 'nush':\n",
    "        print('nush')\n",
    "\n",
    "churn(input_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cert2grade')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7029088697ba5ba005d0c45678542c2099d166a95b0088589fa77b332f24502a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
